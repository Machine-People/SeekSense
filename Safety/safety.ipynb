{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilingual Content Safety Classifier\n",
    "This notebook implements a binary classifier to detect harmful content vs e-commerce queries in both English and Bengali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers torch pandas scikit-learn datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained multilingual model\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=2,\n",
    "    ignore_misatcmhed_sizes=True\n",
    ")\n",
    "\n",
    "# Enable mixed precision training to save memory\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset - expand this with your own data\n",
    "data = {\n",
    "    'text': [\n",
    "        'where can I find the best deals on laptops',\n",
    "        'কিভাবে সিস্টেম হ্যাক করা যায়',  # How to hack system (Bangla)\n",
    "        'shopping cart checkout process',\n",
    "        'ডেটা চুরি করার উপায়',  # Ways to steal data (Bangla)\n",
    "        'অনলাইনে জুতা কিনতে চাই',  # Want to buy shoes online (Bangla)\n",
    "        'best online shopping deals'\n",
    "    ],\n",
    "    'label': [0, 1, 0, 1, 0, 0]  # 0: e-commerce, 1: harmful\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "# Prepare dataset for fine-tuning\n",
    "def prepare_dataset(data):\n",
    "    dataset = Dataset.from_dict(data)\n",
    "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning function with memory optimization\n",
    "def fine_tune(train_dataset, eval_dataset=None):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=4,  # Small batch size for memory efficiency\n",
    "        gradient_accumulation_steps=4,   # Accumulate gradients to simulate larger batch\n",
    "        fp16=True,                      # Use mixed precision training\n",
    "        save_strategy=\"epoch\",\n",
    "        evaluation_strategy=\"epoch\" if eval_dataset else \"no\",\n",
    "        load_best_model_at_end=True if eval_dataset else False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "    )\n",
    "    \n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized inference function\n",
    "def classify_prompt(prompt, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    # Tokenize with padding and truncation\n",
    "    inputs = tokenizer(prompt, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad(), autocast():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class = torch.argmax(predictions, dim=-1)\n",
    "    \n",
    "    return 'Harmful' if predicted_class.item() == 1 else 'E-commerce'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare and fine-tune the model\n",
    "dataset = prepare_dataset(data)\n",
    "train_dataset = dataset.shuffle().select(range(len(dataset) - 1))  # Leave one out for eval\n",
    "eval_dataset = dataset.select(range(len(dataset) - 1, len(dataset)))\n",
    "\n",
    "# Fine-tune the model\n",
    "fine_tune(train_dataset, eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "test_prompts = [\n",
    "    'where can I find the best deals on laptops',\n",
    "    'কিভাবে সিস্টেম হ্যাক করা যায়',  # How to hack system (Bangla)\n",
    "    'shopping cart checkout process optimization',\n",
    "    'ডেটা চুরি করার উপায়',  # Ways to steal data (Bangla)\n",
    "]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    result = classify_prompt(prompt)\n",
    "    print(f'Prompt: {prompt}')\n",
    "    print(f'Classification: {result}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
